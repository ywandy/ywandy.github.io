<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[kubernetes部署-多虚拟机部署]]></title>
    <url>%2Fkubernetes%E9%83%A8%E7%BD%B2-%E5%A4%9A%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%83%A8%E7%BD%B2.html</url>
    <content type="text"><![CDATA[12author: yewei_andyemail: 896882701yw@gmail.com 部署k8s分布式主机配置：虚拟机方案： 使用虚拟机部署3个一样的centos7或者ubuntu虚拟机 配置2张网卡 一张用来主机和虚拟机通讯(host only 网卡),master和node节点通信也是使用这张网卡 一张用来nat和外网通信 三台物理机方案： 三台内网的主机即可，centos7或者ubuntu 配置docker的代理(主要用来拉取镜像使用)1234567891011mkdir -p /etc/systemd/system/docker.service.dcat &lt;&lt;EOF &gt;/etc/systemd/system/docker.service.d/http-proxy.conf[Service]Environment="HTTP_PROXY=http://192.168.56.1:1087/"Environment="HTTPS_PROXY=http://192.168.56.1:1087/"Environment="NO_PROXY=localhost,127.0.0.1,localaddress,.localdomain.com"EOFsystemctl daemon-reloadsystemctl restart docker 测试配置 12docker info | grep Proxy # 有输出说明配置成功docker pull gcr.io/google-containers/hello-world # pull 成功代表代理器工作正常。 配置终端代理(如果有需要)全局终端http/https代理:123456cat &lt;&lt;EOF &gt;&gt;/etc/environmenthttp_proxy="http://&#123;http代理地址&#125;:8118/"https_proxy="http://&#123;http代理地址&#125;:8118/"no_proxy="localhost, 127.0.0.1"EOFsource /etc/environment 仅限当前shell生效的代理(使用export):123export http_proxy="http://&#123;http代理地址&#125;:8118/"export https_proxy="http://&#123;http代理地址&#125;:8118/"export no_proxy="localhost, 127.0.0.1" 修改host.conf文件修改这个文件的目的在于使用主机名都能访问，不需要输入ip地址 三台机都要设置 12345#192.168.56.101 yeweinode1# /etc/hosts&#123;节点1的ip&#125; 节点1的主机名&#123;节点2的ip&#125; 节点1的主机名&#123;节点3的ip&#125; 节点1的主机名 关闭防火墙由于k8s会大量修改防火墙的配置，因此在使用k8s的时候尽量关闭iptables或者防火墙 1234systemctl stop firewalldsystemctl disable firewalldsystemctl stop ufwsystemctl disable ufw 关闭selinux123456# 临时禁用setenforce 0# 永久禁用 vim /etc/selinux/config # 或者修改/etc/sysconfig/selinuxSELINUX=disabled 关闭swap12345# 临时关闭swapoff -a# 注释掉以下字段/dev/mapper/cl-swap swap swap defaults 0 0 如果不想关闭swap的话，需要做以下操作： kubeadm 启动时候需要加入参数 1--ignore-preflight-errors=swap 修改/etc/systemd/system/kubelet.service.d/10-kubeadm.conf 在这个文件加入以下代码: 1Environment="KUBELET_EXTRA_ARGS=--fail-swap-on=false" 使得最后看起来像这样: 命令行程序安装(安装kubectl kubeadm kubelet三个组件)：使用centos: 配置软件源 123456789cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 安装kubelet kubeadm kubectl 12yum install -y kubelet kubeadm kubectlsystemctl enable kubelet &amp;&amp; systemctl start kubelet 使用ubuntu:1234567apt-get update &amp;&amp; apt-get install -y apt-transport-httpscurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.listdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF apt-get updateapt-get install -y kubelet kubeadm kubectl 使用kubeadm启动k8s 在node1(master)中执行 1234kubeadm init --apiserver-advertise-address=&#123;这里填写node1的host-only网卡的地址&#125; --pod-network-cidr=10.244.0.0/16 --ignore-preflight-errors=swap#--apiserver-advertise-address 这个参数是k8s集群中master对外能访问的地址#--pod-network-cidr=10.244.0.0/16 这一节是配置pod的内网网段#--ignore-preflight-errors=swap 如果是使用swap启动的话，需要加这个参数 --apiserver-advertise-address=192.168.56.101 绑定 apiserver 到 master 节点的 Host-Only 适配器的地址，默认是绑到 NAT 的地址上，这样其他机器是永远也访问不到的。 --pod-network-cidr=10.244.0.0/16 指定 pod 网络地址空间，我们使用 flannel 组件必须使用这个空间 等待node1执行结束，会有以下的输出： 配置kubectl，使得能连上k8s的apiserver这时候需要使用kubectl接入kubernets的api，在我们刚刚的kubeadm init时候，程序已经为我们创建了kubectl的配置文件，这时候我们只需要export到环境变量即可 1234567891011121314151.如果是root用户的话# root userexport KUBECONFIG=/etc/kubernetes/admin.conf2.如果是非root用户的话# non-root usermkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config3.如果从其他机器操作的话# 从本地主机操作，需要在本地安装 kubectl 客户端mkdir -p ~/.kubescp &lt;username&gt;@&#123;远端服务器&#125;:/home/&lt;username&gt;/.kube/config ~/.kube/config # 从 master 复制配置文件到本地#把远端服务器的admin.conf拷贝到本地 以上的操作其实是把kubectl需要用到的配置文件配置到kubectl的配置当中 当完成了以上操作后，kuberctl已经能使用了 在终端输入： 1kubectl cluster-info 会有类似下面的输出： 这时候kubectl命令是已经能正常连上api server，集群也处于可用状态 安装flannel网络 可以通过修改kube-flannel.yml文件去修改flannel的默认监听端口 123456wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml给 /opt/bin/flanneld 命令添加 --iface="br0" 参数 #按照实际情况进行配置（一般情况下不需要）kubectl apply -f kube-flannel.yml 测试配置 123kubectl get pods --all-namespaces -o wide # 稍等一会，下载镜像需要一定时间，#最后应该显示 flannel pods 是 Running 状态， kube-dns 也是 Running 状态 ​ 如图： 让master节点也参与调度如果需要在master也进行pod调度（k8s默认不进行pod调度) 执行以下指令 123# taint命令用于配置污点#k8s通过设定是否能容忍污点kubectl taint nodes --all node-role.kubernetes.io/master- 其他节点加入集群 此时需要在要加入集群的服务器上面执行以下指令（当然网段要能访问到,并且已经安装了kubeadm） 1kubeadm join xxxxxxxxx:6443 --token xxxxxx.xxxxxxxx --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxx 这时候会出现以下的信息，说明已经成功加入了集群 安装和配置kubernetes-dashboard安装kubernetes-dashboard 下载官方kubernetes-dashboard的k8s资源文件 1curl -L http://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml -O 把资源文件应用到k8s集群 1kubectl create -f kubernetes-dashboard.yaml 等待dashboard 完全启动，使用以下命令确认 此时，kubernetes-dashboard已经部署 配置kubernetes-dashboard的rbac策略kubernetes-dashboard比较坑的地方在于 如果没有配置策略，那么在启动kubernetes-dashboard的时候会出现很多的warning，然后即使能登陆到kubernetes-dashboard，也无法访问里面的资源 配置rbac策略 1234567891011121314151617181920#admin-user-admin.rbac.yamlapiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system---# Create ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 应用rbac策略到k8s集群 1kubectl create -f admin-user-admin.rbac.yaml 得到用于登陆dashboard的secret 运行命令 1kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user|awk '&#123;print $1&#125;') 会得到以下的token 12345678910111213Name: admin-user-token-hmctlNamespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 00774986-5066-11e9-a0e8-fe242749c541Type: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: xxxxxxxxxxxxx 使用kubectl proxy在本地打开dashboard1kubectl proxy 访问dashboard 本地浏览器地址栏输入: localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ 会出现如下的页面: 输入刚刚拿到的令牌 如果没有配置rbac策略，在这个时候，使用令牌即使以admin-user登陆进去，也不能访问里面的资源 然后进入dashboard界面，如下: 此时，已经可以正常访问了]]></content>
      <categories>
        <category>容器技术</category>
        <category>环境安装</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>环境搭建</tag>
        <tag>docker</tag>
        <tag>kubernetes</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu18.04安装cuda10和cudnn7.5]]></title>
    <url>%2Fubuntu18-04%E5%AE%89%E8%A3%85cuda10%E5%92%8Ccudnn7-5.html</url>
    <content type="text"><![CDATA[ubuntu18.04部署cuda 10和cudnn 7.5cuda安装： 先按照正确方法安装上显卡驱动（cuda版本和显卡驱动要在官网进行确定） 去这个网站下载cuda https://developer.nvidia.com/cuda-toolkit-archive 选择linux-&gt;x86_64-&gt;Ubuntu-&gt;18.04-&gt;run file(local) 进行下载 在服务器执行这个程序,按照提示安装，注意不要安装显卡驱动就好了 cudnn安装： 注册nvidia的开发者账号 在这个页面 https://developer.nvidia.com/rdp/cudnn-download 下载cudnn7.6 此时会下载一个tgz压缩包 在服务器中 12tar zxvf cudnn-10.0-linux-x64-v7.5.0.56.tgzcp cuda/* /usr/local/cuda-10.0 -r 复制过去后，已经完成cudnn库的安装 环境变量的设定 在 /etc/profile 以及自己的bashrc中(~/.bashrc或者~/.zshrc)加入以下信息 1234export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATHexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/libexport PATH=/usr/local/cuda/bin:$PATHexport LD_PRELOAD=/lib/x86_64-linux-gnu/librt.so.1 重启服务器 测试12345678910111213141516171819202122232425# yewei @ DI-ROG in ~ [16:15:21]$ python3Python 3.6.7 (default, Oct 22 2018, 11:32:17)[GCC 8.2.0] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; tf.Session()2019-04-12 16:15:27.733171: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA2019-04-12 16:15:27.800581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2019-04-12 16:15:27.801337: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1ae2960 executing computations on platform CUDA. Devices:2019-04-12 16:15:27.801356: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.12019-04-12 16:15:27.821878: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz2019-04-12 16:15:27.822543: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x21a6e90 executing computations on platform Host. Devices:2019-04-12 16:15:27.822565: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;2019-04-12 16:15:27.822785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.645pciBusID: 0000:01:00.0totalMemory: 7.93GiB freeMemory: 138.88MiB2019-04-12 16:15:27.822800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 02019-04-12 16:15:27.823532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:2019-04-12 16:15:27.823543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 02019-04-12 16:15:27.823547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0: N2019-04-12 16:15:27.823678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 138 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)&lt;tensorflow.python.client.session.Session object at 0x7f94f9a04b00&gt;&gt;&gt;&gt; 证明cuda和cudnn正常安装]]></content>
      <categories>
        <category>环境安装</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker日志清理方法]]></title>
    <url>%2Fdocker%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[docker 日志清理方法12author : yewei_andyemail : 896882701yw@gmail.com 方法1: 使用脚本定期清理(手动删除docker 容器的log文件) 找出docker容器的日志大小： 12345678#!/bin/shecho "======== docker containers logs file size ========" logs=$(find /var/lib/docker/containers/ -name *-json.log) for log in $logs do ls -lh $log done 删除docker容器日志： 12345678910111213#!/bin/sh echo "======== start clean docker containers logs ========" logs=$(find /var/lib/docker/containers/ -name *-json.log) for log in $logs do echo "clean logs : $log" cat /dev/null &gt; $log done echo "======== end clean docker containers logs ========" 方法2: 通过设定docker容器的日志大小(达到容量会自动清理) 使用docker-compose 设定： 1234567nginx: image: nginx:1.12.1 restart: always logging: driver: “json-file” options: max-size: “5g” 使用docker全局配置： 12345# vim /etc/docker/daemon.json&#123; "log-driver":"json-file", "log-opts": &#123;"max-size":"500m", "max-file":"3"&#125;&#125;]]></content>
      <categories>
        <category>容器技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker清除中间镜像的方法]]></title>
    <url>%2Fdocker%E6%B8%85%E9%99%A4%E4%B8%AD%E9%97%B4%E9%95%9C%E5%83%8F%E7%9A%84%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[docker清除中间镜像的方法12author : yewei_andyemail : 896882701yw@gmail.com 我们知道，使用docker的时候，经常会构建出中间镜像，中间镜像如果没有被删除的话，会占用很多的空间资源 删除中间镜像： 使用以下命令删除中间镜像： 1docker rmi $(docker images | grep "^&lt;none&gt;" | awk "&#123;print $3&#125;") 可以先用以下命令查看是否有中间镜像 1docker images | grep "^&lt;none&gt;" | awk "&#123;print $3&#125;"]]></content>
      <categories>
        <category>容器技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决hexo博客的Next主题busuanzi_count失效方法]]></title>
    <url>%2F%E8%A7%A3%E5%86%B3hexo%E5%8D%9A%E5%AE%A2%E7%9A%84Next%E4%B8%BB%E9%A2%98busuanzi-count%E5%A4%B1%E6%95%88%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[2018-10后，无法使用卜算子的统计功能 原因：进入卜算子的官网，发现有两行重要提示： ”因七牛强制过期『dn-lbstatics.qbox.me』域名，与客服沟通无果，只能更换域名到『busuanzi.ibruce.info』！“ 解决方案：替换卜算子在next主题插件里面的域名 hexo-theme-next主题中使用了dn-lbstatics.qbox.me域名的文件位置为： themes\next\layout_third-party\analytics\busuanzi-counter.swig 修改 busuanzi-counter.swig 12345#把以下代码&lt;script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt;#替换成&lt;script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt; 随后重新生成和部署博客，即可看到卜算子功能修复]]></content>
      <categories>
        <category>随手写写</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链的共识算法]]></title>
    <url>%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[区块链分类：公有链：公有链通常也称为非许可链（Permissionless Blockchain），任何人都可以参与区块链数据维护和读取，容易部署应用程序，完全去中心化不受任何机构控制。 公有链是真正意义上的完全去中心化的区块链，它通过密码学保证交易不可篡改，同时也利用密码学验证以及经济上的激励，在互为陌生的网络环境中建立共识，从而形成去中心化的信用机制。在公有链中的共识机制一般是工作量证明（PoW）和权益证明（PoS） 。 联盟链：联盟链是一种需要注册许可的区块链，这种区块链也称为许可链（Permissioned Blockchain）。联盟链仅限于联盟成员参与，联盟规模可以大到国与国之间，也可以是不同的机构企业之间。 区块链上的读写权限、参与记账权限按联盟规则来制定。整个网络由成员机构共同维护，网络接入一般通过成员机构的网关节点接入，共识过程由预先选好的节点控制。因此联盟链一般不采用工作量证明的挖矿机制，而是多采用权益证明（PoS）或PBFT（Practical Byzantine Fault Tolerant）、RAFT等共识算法。 、 私有链：指其写入权限由某个组织和机构控制的区块链，参与节点的资格会被严格限制。由于参与节点是有限和可控的，因此私有链往往可以有极快的交易速度、更好的隐私保护、更低的交易成本、不容易被恶意攻击，并且能做到身份认证等金融行业必需的要求。相比中心化数据库，私有链能够防止机构内单节点故意隐瞒或者篡改数据，即使发生错误，也能够迅速发现来源。因此许多大型金融机构在目前更加倾向于使用私有链技术。 私有链的价值主要是提供安全、可追溯、不可篡改、自动执行的运算平台，可以同时防范来自内部和外部对数据的安全攻击，这个在传统的系统是很难做到的。 共识算法分类：一、工作量证明（PoW）：代表项目：比特币（BTC)为了实现对交易打时间戳，Hash交易数据。比特币用了工作量证明方法。网络中的每个节点从事于解决一个适度困难的密码难题。难题的解决方法是：把区块中的所有数据做SHA256哈希运算，并且得到哈希值小于给定的目标值。区块中还包含一个Nonce值，通过递增Nonce来寻找正确的哈希值。这个密码谜题被设计成，每隔10Mins会找到一个谜题答案。一旦正确的哈希值被找到，节点就会向网络中广播这个哈希值。这个哈希值可以很容易的被网络中的其他节点验证，节点可以对收到区块后对区块中的数据进行SHA256运算哈希值。要修改一个区块需要重做这个区块以及这个区块之后所有区块的工作量证明 。 例如： ​ 这个密码难题是给定一个字符串“hello world”对字符串进行SHA256计算，如果得到hash为0000开头，那么验证通过，那么节点需要对字符串进行SHA256计算 二、DPOS算法：代表项目：EOSPOW的缺陷： 矿池导致算力越来越集中 电力耗费过大 受托人的节点服务器相当于比特币网络里的矿机，在完成本职工作的同时可以领取区块奖励和交易的手续费。 一个区块链项目的受托人个数由项目发起方决定，一般是101个受托人。任何一个持币用户都可以参与到投票和竞选受托人这两个过程中。用户可以随时投票、撤票，每个用户投票的权重和自己的持币量成正比。投票和撤票可以随时进行，在每一轮(round)选举结束后，得票率最高的101（一般为101，也可以是其他数字，具体由区块链项目方决定）个用户则成为该项目的受托人，负责打包区块、维持系统的运转并获得相应的奖励。 选举的根本目的，是通过每个人的投票选举出社区里对项目发展和运行最有利的101个用户。这101个用户的服务器节点既可以高效维护系统的运转，而他们也会贡献自己的能力促进区块链项目的发展 三、消逝时间量证明POET：代表项目：Hyperledger Sawtooth每个节点在发布块以前都要从encalve（使用安全的CPU指令）获取一个随机等待时间，等待时间最短的先发布块，encalve有两个函数，一个是CreateTimer和CheckTimer，第一个是产生一个定时器，另一个是校验定时器是否合法，如果合法将会生成一个凭证，凭证可以用来校验这个随机时间是否使用encalve产生以及是否经过了这个随机等待时间 四、股权证明机制POS：代表项目：以太坊POS的核心是使用币龄，假设每个币每天产生1币龄，或者当你挖出一个块能直接清空币龄，当365币龄被清空，就能获得0.05个币的利息（年利率5%），其余的基本和POW是类似，基于工作量去证明。 设计初衷： 比特币区块产量4年减半，挖矿难度变大，使得矿工可能人数变少，POS采用利息，而且必须打开POS客户端才能获得利息，使得网络节点数量处于健壮状态 由于有部分货币是利息产生，也就是即使有51%货币也不一定能造成51%攻击 解决了比特币的通货紧缩问题 五、拜占庭容错PBFT：代表项目：Hyperledger FabricPBFT算法要求至少要4个参与者，一个被选举为军长，3个师长。军长接到总司令命令：你们向前行军500公里。军长就会给3个师长发命令向前行军500公里。3个师长收到消息后会执行命令，并汇报结果。A师长说我在首都以东500公里，B师长说我在首都以东500公里，C师长说我在首都以东250公里。军长总结3个师长的汇报，发现首都以东500公里占多数（2票&gt;1票），所以就会忽略C师长的汇报结果，给总司令汇报说，好了，现在部队是在首都以东500公里了。这就是PBFT算法。 PBFT算法的核心理论是n&gt;=3f+1 n是系统中的总节点数，f是允许出现故障的节点数。换句话说，如果这个系统允许出现f个故障，那么这个系统必须包括n个节点，才能解决故障。 五个概念： client：请求（request）自愿者，上例中指总司令。 replica：副本，所有参与提供服务的节点，上例指军长和师长 primary：承担起提供服务主要职责的节点，上例是军长 backup：其他副本，但相对于primary角色。上例指师长。 view：处于存在primary-bakup场景中的相对稳定的关系，叫视图。 如果primary出现故障，这种相对稳定的视图关系就会转变（transit）。比如军长叛逃（出现故障，对外表现为不可见），那么某个师长就会转变成为军长。系统也就从视图a转变为视图b（a,b均为整数）。 四个阶段： 请求(request)：client请求阶段（有些说法不包括这个阶段）。总司令给军长下命令。 预准备(pre-prepare)：主节点向所有backup节点发送预准备消息，其中包括当前视图编号，client请求以及请求摘要，签名是否一致等。军长对各位师长说：现在是我的View（视图），我是军长，你们都是师长，所有人都得听我的。现在公布总司令的命令（先说说总司令是谁，命令摘要）。 准备(prepare)：包括主节点在内的所有副本节点在收到准备消息之后，对消息的签名是否正确，视图编号是否一致，以及消息序号是否满足水线限制这三个条件进行验证，如果验证通过则把这个准备消息写入消息日志中。backup节点核对签名信息，比如其他师长听到总司令的名字，说对，总司令就是这个人没错，然后核对总司令曾经任命这家伙当军长，好吧，那就听他的吧。 确认(commit)： 每个副本接受确认消息的条件是： 签名正确 消息的视图编号与节点的当前视图编号一致 消息的序号n满足水线条件 在h和H之间。一旦确认消息的接受条件满足了，则该副本节点将确认消息写入消息日志中。每个师长都经过上述核对，确认无误，就会接受命令进行执行。 六、Hyperledger Kafka(分布式队列)：设计思路：kafka是一个分布式高可用消息队列，可以有序的管理消息并在多个冗余副本间保证数据一致性。kafka集群的状态由zookeeper管理，选举leader节点。 orderer服务从kafka集群里获取相应topic（kafka的分区，用于在队列里隔离出多个数据域）的数据，以保证交易数据有序，借助了kafka的分布式一致机制。如下图： kafka和orderer通讯流程： Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息 Orderer通过Recv接口接收Peer发送过来的消息，并将消息推送到Kafka 同时与Kafka相连接的Orderer通过Consumer实例消费Kafka上的消息，将消费的消息进行同一排序（Order） 排序完成后，当达到生成数据块（Block）的条件: 下一数据块定时器到期，定时器通过向Orderer向Kafka发送定时器消息，再通过Kafka消费来达到定时效果(Batch Timeout)。 每消费一条真实数据，就触发判断是否达到生成一个新的数据块条件(Batch Size)，该条件由当前待生成数据块的数据总的大小以及记录数决定），并创建新的数据块（CreateNextBlock），创建成功则将数据块写入ledger（WriteBlock）。 七、 Hyperledger Solo(单节点排序):order-solo模式作为单节点通信模式，所有从peer收到的消息都在本节点进行排序与生成数据块，详细流程见下图： solo-order的通信流程： Peer（客户端）通过GRPC发起通信 与Orderer连接成功之后，便可以向Orderer发送消息。 Orderer通过Recv接口接收Peer发送过来的消息，Orderer将接收到的消息生成数据块，并将数据块存入ledger peer通过deliver接口从orderer中的ledger获取数据块。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>共识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步一步入门Hyperledger-composer-学习Playground]]></title>
    <url>%2F%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E5%85%A5%E9%97%A8Hyperledger-composer-%E5%AD%A6%E4%B9%A0Playground.html</url>
    <content type="text"><![CDATA[Playground 教程:介绍：我们将使用定义的fabric网络，并且把使用Hyperledger Composer 基于我们的fabric网络构建一个业务网络（business network ），同时我们一步一步完成从创建资产、创建参与者、编写智能合约把一个用户的资产转让给另外一个用户。在这个教程，将会使用Hyperledger Composer里面的套件——composer-playground。 目标: 使用Fabric搭建一个简单的网络 启动composer-playground并使用web沙盒编写和调试代码 创建资产（Asset） 创建参与者（Participants） 编写智能合约代码（Logic）用于资产的归属权更改 测试完成后把.bna文件导出，部署到刚刚的Fabric真实网络 使用composer-playground去连接部署上去的业务网络 实践:一、使用Fabric搭建一个简单的网络： 进入fabric网络一键脚本的repo，然后执行startFarbic.sh： 1./startFabric.sh 此时会刷新出类似一下的信息: 12345678910111213Creating network &quot;composer_default&quot; with the default driverCreating orderer.example.com ... doneCreating ca.org1.example.com ... doneCreating couchdb ... doneCreating mongodb ... doneCreating peer0.org1.example.com ... donesleeping for 15 seconds to wait for fabric to complete start up2018-08-21 22:31:08.469 CST [msp] GetLocalMSP -&gt; DEBU 001 Returning existing local MSP2018-08-21 22:31:08.469 CST [msp] GetDefaultSigningIdentity -&gt; DEBU 002 Obtaining default signing identity2018-08-21 22:31:08.471 CST [channelCmd] InitCmdFactory -&gt; INFO 003 Endorser and orderer connections initialized.........................................................2018-08-21 22:31:08.958 CST [channelCmd] executeJoin -&gt; INFO 006 Successfully submitted proposal to join channel2018-08-21 22:31:08.958 CST [main] main -&gt; INFO 007 Exiting..... 只需要看到最后面出现了successfully即可 等待网络完全启动完成，执行createPeerAdminCard.sh: 1./createPeerAdminCard.sh 这步会把创建composer的PeerAdmin Card（具体用途将在以后章节详细讲解），只需知道，需要有这个card才能接下来完成composer业务网络部署到真实的fabric网络。这个脚本会自动完成这一系列操作，执行了这个脚本，将会有类似以下的输出： 1234567891011121314151617181920212223242526272829303132Development only script for Hyperledger Fabric controlRunning 'createPeerAdminCard.sh'FABRIC_VERSION is unset, assuming hlfv11FABRIC_START_TIMEOUT is unset, assuming 15 (seconds)Using composer-cli at v0.19.12Successfully created business network card file to Output file: /tmp/PeerAdmin@hlfv1.cardCommand succeededSuccessfully imported business network card Card file: /tmp/PeerAdmin@hlfv1.card Card name: PeerAdmin@hlfv1Command succeededThe following Business Network Cards are available:Connection Profile: hlfv1┌─────────────────┬───────────┬──────────────────┐│ Card Name │ UserId │ Business Network │├─────────────────┼───────────┼──────────────────┤│ PeerAdmin@hlfv1 │ PeerAdmin │ │└─────────────────┴───────────┴──────────────────┘Issue composer card list --card &lt;Card Name&gt; to get details a specific cardCommand succeeded 我们可以使用 composer card list 去验证一下，同时使用composer card list --card PeerAdmin@hlfv1 可以返回具体的card信息 1234567891011121314➜ fabric-dev-servers git:(master) ✗ composer card list --card PeerAdmin@hlfv1userName: PeerAdmindescription:businessNetworkName:identityId: 114aab0e76bf0c78308f89efc4b8c9423e31568da0c340ca187a9b17aa9a4457roles: - PeerAdmin - ChannelAdminconnectionProfile: name: hlfv1 x-type: hlfv1credentials: Credentials setCommand succeeded 二、启动composer-playground：只需要在命令行输入composer-playground: 1composer-playground 会有以下的输出: 123➜ fabric-dev-servers git:(master) ✗ composer-playgroundinfo: [Hyperledger-Composer] :LoadModule :loadModule() Loading composer-wallet-filesystem from /home/wwb/xinou-network/node_modules/composer-wallet-filesysteminfo: [Hyperledger-Composer] :PlaygroundAPI :createServer() Playground API started on port 8080 说明正确启动，并且监听**8080**端口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071然后访问浏览器的http://localhost:8080 即可访问composer-playground的web页面![composer-playground-overview](http://storage.ywandy.top/yewei-photo/180821/lm1GgaFf4G.png)### 三、启动web沙盒环境并调试代码：1. 点击进入如图所示区域，就是web沙盒的区域： ![mark](http://storage.ywandy.top/yewei-photo/180821/5B03hl3aeI.png)2. 按照以下填写我们的**tutorial-network**，并且点击**depoly** 1. 这一步将会启动一个空的业务网络 2. 这个业务网络的名字叫做**turtorial-network** 3. 这个业务被**depoly**，默认的业务网卡（暂时有且只有一个）的是**admin@turtorial-network** (业务网卡这边以后会有专门的章节讲解) ![mark](http://storage.ywandy.top/yewei-photo/180821/AeBbdAamfi.png)3. 此时等depoly完成后，点击connect即可进入在线的沙盒环境： ![mark](http://storage.ywandy.top/yewei-photo/180821/BdeCbB5kA5.png) ![mark](http://storage.ywandy.top/yewei-photo/180821/1C9K5hAl2j.png)### 三、创建资产和参与者：#### 文件目录： - 模型文件 (.cto) （定义 Assets, Participants 和Transactions）- 智能合约(.js) （使用JavaScript定义执行Transaction）- Query查询文件(.qry) (定义couchdb的queries查询语句)- 访问权限控制文件(permissions.acl) (定义权限访问控制的文件)#### 编写模型文件代码：1. 在`model.cto`文件里面输入以下代码: ```js namespace org.example.mynetwork //定义网络名 asset Commodity identified by tradingSymbol &#123; //定义一个资产 o String tradingSymbol o String description o String mainExchange o Double quantity --&gt; Trader owner &#125; participant Trader identified by tradeId &#123; //定义一个参与者 o String tradeId o String firstName o String lastName &#125; transaction Trade &#123; //定义一个transaction的数据结构 --&gt; Commodity commodity --&gt; Trader newOwner &#125; 编写一个智能合约代码：我们需要一个交易资产的智能合约，需要使用js实现这个。目前我们的composer-playground并没有这个script.js 我们点击add file，然后选择script file 随后我们会进入script.js，这时候可以把代码编写进那个在线的IDE 把以下代码复制进入script.js： 12345678910/** * Track the trade of a commodity from one trader to another * @param &#123;org.example.mynetwork.Trade&#125; trade - the trade to be processed * @transaction */async function tradeCommodity(trade) &#123; trade.commodity.owner = trade.newOwner; //通过把原本资产的owner设置成传参的新的owner let assetRegistry = await getAssetRegistry('org.example.mynetwork.Commodity'); //获取资产的对象 await assetRegistry.update(trade.commodity); //资产更新&#125; 四、部署网络并且测试:沙盒部署： 点击右下角的Depoly changes 这时候会提示部署成功，然后点击正上方的标签栏Test 进入测试的页面，如图： 沙盒调试： 选中Trader，然后点击右上角的 Create new participant，然后会弹出界面，输入以下的代码: 123456&#123; "$class": "org.example.mynetwork.Trader", "tradeId": "TRADER1", "firstName": "Jenny", "lastName": "Jones"&#125; 点击确认后，再次重复刚刚步骤，并输入以下的代码: 123456&#123; "$class": "org.example.mynetwork.Trader", "tradeId": "TRADER2", "firstName": "Amy", "lastName": "Williams"&#125; 以上的代码作用是创建两个交易者，一个是Jenny Jones，他的tradeid是TRADER1，另一个是Williams Amy ，他的tradeid是TRADER2（在这个定义交易者的数据结构，是使用tradeID作为主键的，关于模型文件的讲解会在以后的章节讲解到） 选中Commdity然后点击右上角的Create new asset，并输入以下代码： 123456789&#123; "$class": "org.example.mynetwork.Commodity", "tradingSymbol": "ABC", "description": "Test commodity", "mainExchange": "Euronext", "quantity": 72.297, "owner": "resource:org.example.mynetwork.Trader#TRADER1"&#125; 这时候会创建一个叫做ABC的资产，属于TRADER1的，也就是Jenny Jones的 提交transaction，把物品ABC从TRADER1交易给TRADER2 点击Submit Transaction，然后确保Type选中Trade，然后输入以下代码: 12345&#123; "$class": "org.example.mynetwork.Trade", "commodity": "resource:org.example.mynetwork.Commodity#ABC", "newOwner": "resource:org.example.mynetwork.Trader#TRADER2"&#125; 如图： 当点击submit后，成功后会有以下提示: 说明交易已经成功了，我们看这条ABC的条目，发现owner已经变成TRADER2了，说明提交智能合约成功了，并且实现了智能合约更改物品的归属权。 打包并且导出当前业务网络为.bna文件:.bna文件可以用于使用composer命令行工具，实现业务网络的安装和更新，因此我们在沙盒测试完成后，需要导出这个.bna，才能用于后续的命令行部署到真实的fabric网络 点击Define，回到原来编写代码的标签页 点击新增文件右边的export，即可获得当前业务网络的.bna文件]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>hyperledger</tag>
        <tag>composer</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO语言的变量]]></title>
    <url>%2FGO%E8%AF%AD%E8%A8%80%E7%9A%84%E5%8F%98%E9%87%8F.html</url>
    <content type="text"><![CDATA[GO语言的变量（1）变量的声明:一、指定变量类型(如果不赋值，会有默认值):12345var v_name v_typevar test1 string //没赋值，初始值为""空字符串var test2 int //没赋值，初始值为0var test3 string = "test2" //赋值了，为"test2" String 二、根据值自行判定变量的类型：123var v_name = valuevar test4 = "test4" //自动判断变量的类型,为"test4" String 三、省略var，使用:=直接赋值(左侧变量不能为声明过的，且只能在函数体内使用)：1test5 := "test5" 实例程序:123456789101112131415package mainimport "fmt"var test1 string //没赋值，初始值为""空字符串var test2 int //没赋值，初始值为0var test3 string = "test2" //赋值了，为test2var test4 = "test4" //自动判断变量的类型func main()&#123; test5 := "test5" fmt.Println(test1,test2,test3) //打印第一种情况 fmt.Println(test4) //打印第二种情况 fmt.Println(test5) //打印第三种情况&#125; 得到程序的输出: 1230 test2 //打印第一种情况test4 //打印第二种情况test5 //打印第三种情况 （2）多变量的声明:声明规则：12345678910111213//类型相同多个变量, 非全局变量var vname1, vname2, vname3 typevname1, vname2, vname3 = v1, v2, v3var vname1, vname2, vname3 = v1, v2, v3 //和python很像,不需要显示声明类型，自动推断vname1, vname2, vname3 := v1, v2, v3 //出现在:=左侧的变量不应该是已经被声明过的，否则会导致编译错误// 这种因式分解关键字的写法一般用于声明全局变量var ( vname1 v_type1 vname2 v_type2) 实例代码：123456789101112131415package mainvar x, y intvar ( a int b bool)var c, d int = 1, 2var e, f = 123, "hello world"func main()&#123; g, h := 456, "hello go" println(x,y,a,b,c,d,e,f,g,h)&#125; 得到程序的输出： 10 0 0 false 1 2 123 hello world 456 hello go （3）值的类型和引用类型 所有像 int、float、bool 和 string 这些基本类型都属于值类型，使用这些类型的变量直接指向存在内存中的值： 当使用等号 = 将一个变量的值赋值给另一个变量时，如：j = i，实际上是在内存中将 i 的值进行了拷贝： 可以通过 &amp;i 来获取变量 i 的内存地址。值类型的变量的值存储在栈中。内存地址会根据机器的不同而有所不同，甚至相同的程序在不同的机器上执行后也会有不同的内存地址。因为每台机器可能有不同的存储器布局，并且位置分配也可能不同。 一个引用类型的变量 r1 存储的是 r1 的值所在的内存地址（数字），或内存地址中第一个字所在的位置。 如图： 这个内存地址称为指针，实际上是存在另外的某一个字里面 同一个引用类型的指针指向的多个字可以是在连续的内存地址中（内存布局是连续的），这也是计算效率最高的一种存储形式；也可以将这些字分散存放在内存中，每个字都指示了下一个字所在的内存地址。 当赋值语句r2 = r1，只是复制引用地址： 实例代码: 12345678910111213141516package mainvar v1 int = 1var v2 int = 2var v3, v4 = v1, v2 //v3,v4为v1 v2的拷贝var v5, v6 = &amp;v1, &amp;v2 //v5,v6为v1 v2的引用func main()&#123; println(v1," ",v2)//打印原值v1 v2 println(v3," ",v4) //打印拷贝的v1 v2 println(v5," ",v6) //打印v1 v2的引用 println(*v5," ",*v6) //打印v1 v2的解引用（引用的地址的值） v2 = 3 // 修改v2为3 println(*v5," ",*v6) //打印v1 v2的解引用（引用的地址的值） println(v3," ",v4) //打印拷贝的v1 v2&#125; 程序输出: 1234561 2 //打印原值v1 v21 2 //打印拷贝的v1 v20x49d138 0x49d140 //打印v1 v2的引用1 2 //打印v1 v2的解引用（引用的地址的值）1 3 //打印v1 v2的解引用（引用的地址的值）(修改v2为3后) 发现变化了1 2 //打印拷贝的v1 v2，因为不是引用，因此不会变化]]></content>
      <categories>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fabric在阿里云安装出现的一些问题解决]]></title>
    <url>%2FFabric%E5%9C%A8%E9%98%BF%E9%87%8C%E4%BA%91%E5%AE%89%E8%A3%85%E5%87%BA%E7%8E%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3.html</url>
    <content type="text"><![CDATA[Hyperledger Fabric在阿里云安装出现的一些问题解决1. [signal SIGSEGV: segmentation violation code=0x1 addr=xxx pc=xxx] 类似的错误:原始错误的代码(来自peer节点):123456789101112132018-08-19 22:43:43.665 CST [couchdb] handleRequest -&gt; WARN 016 Retrying couchdb request in 125ms. Attempt:1 Error:Get http://couchdb:5984/: dial tcp 172.18.0.4:5984: getsockopt: connection refused2018-08-19 22:43:43.790 CST [couchdb] handleRequest -&gt; DEBU 017 HTTP Request: GET / HTTP/1.1 | Host: couchdb:5984 | User-Agent: Go-http-client/1.1 | Accept: multipart/related | Accept-Encoding: gzip | |fatal error: unexpected signal during runtime execution[signal SIGSEGV: segmentation violation code=0x1 addr=0x63 pc=0x7f17e8243259]runtime stack:runtime.throw(0xf11259, 0x2a) /opt/go/src/runtime/panic.go:605 +0x95runtime.sigpanic() /opt/go/src/runtime/signal_unix.go:351 +0x2b8goroutine 88 [syscall, locked to thread]:runtime.cgocall(0xbf3800, 0xc42028fac8, 0xf0fa21) 解决方法:修改自己阿里云ecs机器里面的/etc/resolv.conf，把里面的 options timeout:2 attempts:3 rotate single-request-reopen 这一行内容注释掉 :例如我的/etc/resolv.conf : 12345# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)# DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTENnameserver 100.100.2.136nameserver 100.100.2.138#options timeout:2 attempts:3 rotate single-request-reopen 然后问题就解决了 原因解析:这个问题是出在go的DNS解析问题，由于go的Resolver不支持options single-request-reopen从而走了CGO Resolver方法导致失败了，因此只需要把/etc/resolv.conf里面的single-request-reopen这一行注释掉即可 参考为什么通过CGO Resolver失败的原因: Static Cgo Builds, What Could Go Wrong?]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>hyperledger</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下GO环境安装]]></title>
    <url>%2FLinux%E4%B8%8BGO%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[Linux 下GO 环境安装:安装环境: 从Golang DL下载go1.10.3.linux-amd64.tar.gz https://dl.google.com/go/go1.10.3.linux-amd64.tar.gz```12342. 解压`go1.10.3.linux-amd64.tar.gz` ```tar zxvf go1.10.3.linux-amd64.tar.gz 移动go到/usr/local golink124. 在`~/.profile`加入环境变量: export PATH=$PATH:/usr/local/go/binexport PATH=$PATH:$GOROOT/bin 1234567891011121314151617181920212223242526275. 在家目录下建立go目录: `mkdir -p ~/go ` 6. 创建一个工程路径（GOPATH)例如我在家目录创建work路径： `mkdir ~/work -p`7. 加入`~/work`到.profile环境变量： ```export GOPATH=~/work``` 8. 使.profile生效: `source ~/.profile` ### 测试环境:1. 在命令行打入`go version`可以看到类似: ```bash # yewei @ xinou-work in ~/yyw/fabric/work [9:58:07] $ go version go version go1.10.3 linux/amd64 在命令行打入go env可以看到类似: 12345678910111213141516171819202122232425# yewei @ xinou-work in ~/yyw/fabric/work [10:00:50]$ go envGOARCH="amd64"GOBIN=""GOCACHE="/home/yewei/.cache/go-build"GOEXE=""GOHOSTARCH="amd64"GOHOSTOS="linux"GOOS="linux"GOPATH="/home/yewei/yyw/fabric/work"GORACE=""GOROOT="/home/yewei/go"GOTMPDIR=""GOTOOLDIR="/home/yewei/go/pkg/tool/linux_amd64"GCCGO="gccgo"CC="gcc"CXX="g++"CGO_ENABLED="1"CGO_CFLAGS="-g -O2"CGO_CPPFLAGS=""CGO_CXXFLAGS="-g -O2"CGO_FFLAGS="-g -O2"CGO_LDFLAGS="-g -O2"PKG_CONFIG="pkg-config"GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build424194477=/tmp/go-build -gno-record-gcc-switches" 在~/work/创建一个src/hello文件夹，并创建文件hello.go文件，并敲入以下代码: 12345package mainimport "fmt"func main() &#123; fmt.Printf("hello, world\n")&#125; 在~/work/下面执行go install hello，此时会构建src/hello里面的源码，生成bin文件夹]]></content>
      <categories>
        <category>环境安装</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>linux</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fabric的编译安装]]></title>
    <url>%2Ffabric%E7%9A%84%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[安装go可以参照我上一篇博客12345678wget https://dl.google.com/go/go1.10.3.linux-amd64.tar.gztar -xvf go1.10.3.linux-amd64.tar.gzmv go /usr/local/mkdir -p ~/go vim /etc/profileexport GOPATH=~/workexport PATH=$PATH:/usr/local/go/bin:$GOPATH/binsource /etc/profile 安装依赖包12apt-get updateapt-get install -y libsnappy-dev zlib1g-dev libbz2-dev libltdl-dev libtool Fabric源码下载12git clone https://github.com/hyperledger/fabric $GOPATH/src/github.com/hyperledger/fabricgit clone https://github.com/hyperledger/fabric-ca $GOPATH/src/github.com/hyperledger/fabric-ca 或12go get github.com/hyperledger/fabricgo get github.com/hyperledger/fabric-ca 编译fabric代码1234cd $GOPATH/src/github.com/hyperledger/fabricmake nativemake dockercp build/bin/* $GOPATH/bin/ 解决编译fabric过程中报错1. 解决make docker时候报错golang-x-tool错误:错误信息： 1package golang.org/x/tools/go/gcexportdata: unrecognized import path "golang.org/x/tools/go/gcexportdata" 解决方案1git clone https://github.com/golang/tools.git $GOPATH/src/golang.org/x/tool 2. 解决：cp: cannot stat ‘build/docker/gotools/bin/protoc-gen-go’: No such file or directory12345go get github.com/golang/protobuf/protoc-gen-gocd $GOPATH/src/github.com/golang/protobuf/make allcd $GOPATH/src/github.com/hyperledger/fabriccp $GOPATH/bin/protoc-gen-go .build/docker/gotools/bin/ 编译fabric-ca代码1234567cd $GOPATH/src/github.com/hyperledger/fabric-camake dockercd $GOPATH/src/github.com/hyperledger/fabricmake releasemake dockercp .build/bin/* $GOPATH/bin/]]></content>
      <categories>
        <category>环境安装</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>hyperledger</tag>
        <tag>fabric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步一步构建Hyperledger composer 开发环境(二)]]></title>
    <url>%2F%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%9E%84%E5%BB%BAHyperledger-composer-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83-%E4%BA%8C.html</url>
    <content type="text"><![CDATA[安装Hyperledger composer一、安装前准备: 操作系统: ubuntu 14.04/16.04 LTS Docker: 17.03或者更高 Docker-Compose: 1.8或者更高 Node: 8.9 或者更高(大于9.0版本不兼容) npm: v5.x git: 2.9.x 或者更高 代码编辑器，例如Visual Studio Code 二、安装需要的组件:使用以下的命令从网上下载上述的依赖: 123curl -O https://hyperledger.github.io/composer/latest/prereqs-ubuntu.shchmod u+x prereqs-ubuntu.sh./prereqs-ubuntu.sh 以上步骤完成后，就可以开始下面的步骤，安装开发环境. 三、安装开发环境:（1）安装Cli工具:Composer自带了很多的命令行工具。最重要的是composer-cli，它包含所有必要的操作，接下来安装的generator-hyperledger-composer，composer-rest-server以及Yeoman，在构建于业务网络交互的应用程序会很有用。 工具安装: 1npm install -g composer-cli@0.20 REST Server 安装： 1npm install -g composer-rest-server@0.20 生成器的安装： 1npm install -g generator-hyperledger-composer@0.20 Yeoman安装(一个生成应用程序的工具)： 1npm install -g yo （2）安装Playground: 安装composer-playground： 1npm install -g composer-playground@0.20 （3）配置IDE开发环境:我们使用visual studio code去做开发的IDE： 从以下URL安装VSCode：https：//code.visualstudio.com/download 打开VSCode，转到Extensions，然后Hyperledger Composer从Marketplace中搜索并安装扩展程序。 （4）安装Hyperledger Fabric：这个安装步骤提供部署业务网络的本地Hyperledger Fabric运行时 ： 选择一个目录，例如~/fabric-dev-servers，执行以下代码: 123mkdir ~/fabric-dev-servers &amp;&amp; cd ~/fabric-dev-serverscurl -O https://raw.githubusercontent.com/hyperledger/composer-tools/master/packages/fabric-dev-servers/fabric-dev-servers.tar.gztar -xvf fabric-dev-servers.tar.gz进入进入刚刚下载的那个目录: 进入刚刚下载的路径: 123cd ~/fabric-dev-serversexport FABRIC_VERSION=hlfv12./downloadFabric.sh 四、控制你的开发环境:（1）启动和停止Hyperledger Fabric1234cd ~/fabric-dev-serversexport FABRIC_VERSION=hlfv12./startFabric.sh./createPeerAdminCard.sh 停止运行时：~/fabric-dev-servers/stopFabric.sh 启动运行时：~/fabric-dev-servers/startFabric.sh （当运行了停止脚本，下次运行除了执行startFabric.sh，还需要运行createPeerAdminCard.sh （2）启动网络应用程序（playground）1composer-playground 然后使用浏览器访问 http://localhost:8080/login 就可以打开playground 五、干净的销毁网络: 执行stopFabric.sh 先关闭所有的容器: 12cd ~/fabric-dev-servers./stopFabric.sh 执行docker container prune 去消除所有的fabric 容器 执行sudo rm ~/.composer/* -rf清除composer网络残留的一些chaindata文件]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>hyperledger</tag>
        <tag>composer</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步一步构建Hyperledger composer 开发环境 (一)]]></title>
    <url>%2F%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%9E%84%E5%BB%BAHyperledger-composer-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83-%E4%B8%80.html</url>
    <content type="text"><![CDATA[什么是Hyperledger Composer: Hyperledger Composer是一个广泛的开放式开发工具集和框架，可以更轻松地开发区块链应用程序。Hyperledger Composer的主要目标是加快实现价值的速度，并使区块链应用程序与现有业务系统的集成变得更加容易。我们可以使用Composer快速开发用例并在数周内而不是数月内部署区块链解决方案。 Hyperledger Composer允许您对业务网络进行建模，并将现有系统和数据与区块链应用程序集成。 Hyperledger Composer支持现有的Hyperledger Fabric区块链基础架构和运行时 Hyperledger Composer支持可插入的区块链共识协议，以确保指定的业务网络参与者根据策略验证事务。 日常应用程序可以使用来自业务网络的数据，为最终用户提供简单且受控的访问点。 您可以使用Hyperledger Composer快速建模您当前的业务网络，包含您现有的资产以及与之相关的交易; 资产是有形或无形的商品，服务或财产。作为业务网络模型的一部分，您可以定义可与资产交互的事务。业务网络还包括与多个业务网络交互的参与者，每个参与者可以与唯一身份相关联。 Hyperledger Composer的示意图:Hyperledger Composer的基本概念: 区块链状态存储(Blockchain State Storage): 通过业务网络提交的所有事务都存储在区块链分类账中，资产和参与者的当前状态存储在区块链状态数据库中。区块链将分类帐和状态数据库分布在一组对等方中，并使用一致性算法确保对所有对等方的分类帐和状态数据库的更新是一致的。 连接配置文件(Connection Profiles): Hyperledger Composer使用连接配置文件定义要连接的系统。连接配置文件是JSON文档，它是业务网卡的一部分。这些配置文件通常由它们引用的系统的创建者提供，并且应该用于创建业务网卡以便能够连接到该系统。 资产(Assets): 资产是有形或无形的商品，服务或财产，存储在注册管理机构中。资产几乎可以代表商业网络中的任何内容，例如，待售房屋，销售清单，该房屋的土地登记证书，以及该房屋的保险单据都可以是一个或多个商业网络中的资产,资产必须具有唯一标识符，但除此之外，它们可以包含您定义的任何属性。资产可能与其他资产或参与者有关. 参与者(Participants): 参与者是商业网络的成员。他们可能拥有资产并提交交易。参与者类型是建模的，与资产一样，必须具有标识符，并且可以根据需要具有任何其他属性。参与者可以映射到一个或多个身份。 身份(Identities): 身份是数字证书和私钥。身份用于在业务网络上进行交易，并且必须映射到业务网络中的参与者。单个身份存储在业务网卡中，如果该身份已映射到参与者，则允许该业务网卡的用户作为该参与者在业务网络上进行交易。 商务网卡(Business Network cards): 业务网卡是身份，连接配置文件和元数据的组合，元数据可选地包含要连接的业务网络的名称。业务网卡简化了连接到业务网络的过程，并将业务网络外的身份概念扩展到身份的“钱包”，每个身份与特定的业务网络和连接配置文件相关联。 交易(Transactions): 事务是参与者与资产交互的机制。这可以简单到参与者在拍卖中对资产进行投标，或者标记拍卖结束的拍卖者，自动将资产的所有权转移给最高出价者。 查询(Queries): 查询用于返回有关区块链世界状态的数据。查询在业务网络中定义，并且可以包括用于简单定制的变量参数。通过使用查询，可以轻松地从区块链网络中提取数据。使用Hyperledger Composer API发送查询。 活动(Events): 事件在业务网络定义中以与资产或参与者相同的方式定义。一旦定义了事件，它们就可以由事务处理器函数发出，以向外部系统指示分类账发生了重要的事情。应用程序可以通过composer-clientAPI 订阅发出的事件。 访问控制(Access Control): 业务网络可以包含一组访问控制规则。访问控制规则允许对参与者可以访问业务网络中的哪些资产以及在什么条件下进行细粒度控制。访问控制语言足够丰富，可以声明性地捕获复杂的条件，例如“只有车辆的所有者才能转让车辆的所有权”。从事务处理器功能逻辑外部化访问控制使得检查，调试，开发和维护变得更加容易。 历史记录(Historian registry): 历史记录是一个专门的注册表，记录成功的交易，包括提交它们的参与者和身份。历史记录将事务存储为HistorianRecord资产，这些资产在Hyperledger Composer系统命名空间中定义。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>hyperledger</tag>
        <tag>composer</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链——双花问题]]></title>
    <url>%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E2%80%94%E2%80%94%E5%8F%8C%E8%8A%B1%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[什么是双花问题:我们常说，区块链在金融领域，主要是提供了一个解决“双花问题”的方法，我们首先来了解一下，什么是双花问题。“双花”也叫做双重支付，在数字货币系统中，由于数据的可复制性，因此可能导致交易系统中存在同一笔数字资产被重复使用。为什么“双花问题”在数字货币系统中会存在，而在显示的货币中不会存在，我们可以举两个例子： 假设小明拥有20元，他去咖啡店花费了20元购买了一杯咖啡，然后他此时身上是没钱的，然后他想去隔壁超市购买一件20元的商品，而他已经在咖啡店使用了这20元，那他有可能再去购买这20元的商品吗？由于他使用的是现金，显然是不可能的，当然他在买咖啡钱如果能完全复制那20元，就有可能 现在假设小明使用的这20元不是现金，而是数字货币系统，例如他手持了一张20元的银行卡，假设他有能力复制了另一张银行卡，内容是完全一样的，然后，假设小明抓住了提交交易时候银行需要一定时间去处理，小明抓住了这个时间差，在短时间内使用这两张卡消费了，银行会同时收到同一个金额的两笔交易（当然我们要假设银行没有双花防范），这时候，小明使用同一笔钱成功的购买了两件不同的商品 以上的两种情况都是我们所说的双花，广义上，这两种情况都是双花，但是，具体来看，第一种情况是货币本身的问题，第二种情况是交易的问题。当然，实际上，要想在现金实现双花是在太难了，毕竟现金是事物，店员容易辨认现金金额，而数字货币只是数据，在数字交易系统，很容易因为数据的可复制性使得系统存在同一笔数字资产被重复使用的情况。我们可以知道，当一笔数字资产（也叫做token），一个序列号的字符串，被两次或者多次花掉，也就意味着能被更多次花掉，那么这个数字资产就没有任何价值的，因此数字资产更需要注重解决“双花问题”。 非区块链解决方法：当今的银行和第三方中介机构（例如支付宝），都是从货币和交易两方面入手去解决的，以银行为例子，要是从货币的维度解决，假设小明自作聪明的去复制银行卡，他会发现，银行卡是无法复制的，卡的磁道、芯片信息是利用了信息安全加密的，因此无法复制银行卡；要是从交易的维度解决，假设小明实在太牛了，成功的复制了一张银行卡，然后他同时在两地同时消费了同样的金额，这样，在理想情况，银行能同时收到两笔交易请求，但是由于银行系统设定为原子性，因此银行自然会一笔一笔的去处理，理所当然，先处理哪一笔，小明都会标记为已经花费了那笔钱。 我们常用的支付宝/微信的解决方案：我们日常使用比较多的数字货币算是微信支付里面的钱也或者是支付宝里面的钱，事实上支付宝和微信里面的电子现金，并不是数字货币世界的钱（银行的电子现金是），但是却是存在于真实银行的，其实微信和支付宝并不是银行，而是交易的中介机构，当你走进咖啡店想要购买咖啡的时候，若你选择了支付宝或者微信支付，实际上发生了一下几个步骤: 把钱先给支付宝或者微信 支付宝或者微信把钱存在他们账户 当确认这笔交易后，支付宝或者微信会把钱从银行账户取出并且交给商家当你要进行数字货币交易，首先你要把钱交给一个第三方机构，第三方机构去对钱和余额做中心化的管理，并修改用户的余额达到防范“双花”。 常用中介解决方案的漏洞：由于进行“双花”防范是使用中心化的，也就是说，中心中介机构很明确，是微信/支付宝，要是如果这个中介机构被黑客攻陷（当然，这个工作量是非常大，也是非常不可能的）;也有一种可能，由于我们信任一个中心化的中介机构，当然，我们也许信任的不一定是微信/支付宝这种高信誉度的公司，也可能是其他的第三方机构，如果有人恶意篡改数据呢？这样将会使得整个数字货币世界都非常不安全。按照上面的情况看来，我们要转移数字资产，是需要第三方的机构做中介，但是我们是否能够不通过中心化的第三方机构就向别人转移数字资产呢？ 迎刃而生的去中心化共识系统——区块链要是从以上的两个维度，货币和交易本身来讲。从货币的维度来说，首先我们得知道，数字资产在区块链的账户只是一个序列化的hash地址，并且任何一个人都能看到，但是用户是加密的，每个用户都有自己的私钥和公钥（公钥能够通过私钥推出，并且能解码由私钥加密的数据，但是公钥不能反推私钥），因此这样保证了区块链的数字货币是安全的，并且是难以伪造的。其次，从交易的维度来说，区块链引入共识机制，我们常见的有pow，pos，这个也是区块链去中心化的核心思想，用奖励的方式让全网一起参与计算 ，在区块链的世界，要是用户之间要发生一笔交易，那么假设这双方是A和B，那么A要交易一个资产给B的话，需要这样做： 把数字资产p用A的私钥签名并且广播到全网 这时候，提交的资产被称为UTXO，此时的交易是未经过验证的 全网通过A的公钥去验算是否这个数字资产属于A的 当通过后，全网的机器都把数字资产A的具体交易信息记录进入账本（区块链） 由以上的步骤，区块链中全网每一台机器都参与共识过程，全网通过公钥对交易进行所有权验证，区块链从密码学的角度解决了货币本身所有权的问题以及交易的唯一性问题。在使用区块链后，如果小明存在双花问题，那么两笔交易会同时向全网广播，所有的区块链节点会收到广播的请求，同时每个节点上会存在全网所有的区块信息也就是全网的账户信息，来验证小明该交易的合法性。两笔交易一前一后到达那肯定没啥好说的，全网任意一个节点都能验证出第二笔为重复支付；若两笔交易同时达到两个节点中，两个节点同时验证为成功的同时广播到全网，若整个全网一部分阶段收到的第一笔交易，一部分节点收到的是第二笔交易都对本地数据进行了更新，那全网就出现了分叉（区块链账本分叉问题），好在区块链对交易的确认有两点： 存在与最长分支中的block 至少有5个验证过的block再其后面得到验证 所以出现分叉之后，全网的矿工会继续按照自己的区块更新，再之后的几次区块中自然会更新出最长的一条区块来，全网的所有矿工都以最长的区块信息为准。当然这样也不是绝对的，当小明控制了全网超过51%的算力，那么就能实现账本分叉，当然，要控制这么多算力的机器，小明显然也是得付出超过双花本身代价的努力]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>密码学</tag>
        <tag>金融</tag>
        <tag>双花问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bitcoinj库的Hex类型私钥生成公钥java实现-sawtooth的keygen相关代码java实现]]></title>
    <url>%2Fbitcoinj%E5%BA%93%E7%9A%84Hex%E7%B1%BB%E5%9E%8B%E7%A7%81%E9%92%A5%E7%94%9F%E6%88%90%E5%85%AC%E9%92%A5java%E5%AE%9E%E7%8E%B0-sawtooth%E7%9A%84keygen%E7%9B%B8%E5%85%B3%E4%BB%A3%E7%A0%81java%E5%AE%9E%E7%8E%B0.html</url>
    <content type="text"><![CDATA[分析 我们在使用hyperledger sawtooth平台的时候，需要使用keygen这一个sawtooth的cli程序去创建一对密钥对，在hyperledger sawtooth中,该过程是使用一个特定的随机函数，生成一个私钥，再执行Secp256k1椭圆曲线算法，根据私钥导出公钥 我在使用sawtooth的java sdk时候遇到了这样的问题，首先java的sdk 源码(https://github.com/hyperledger/sawtooth-sdk-java) 在sdk的example代码，调用了如下两个函数: 1234567public static ECKey readWif(String wif) &#123; return DumpedPrivateKey.fromBase58(MAINNET, wif).getKey();&#125;public static String getPublicKey(ECKey privateKey) &#123; return ECKey.fromPrivate(privateKey.getPrivKey(), true).getPublicKeyAsHex();&#125; 并且按照example给出的测试集其中一对公钥私钥如下: 12私钥: 5JkisHAXScTk6Tah9jq9S5B4ByiputRjnKnQrF6k1uBLBQAD8Mi 公钥: 03bc976dc770b84decb90abeb94364c6368da051a9417cc4046f9f478d995b2ba7 按照以上的调用，通过readWif(String wif) 把私钥导入，确实能够生成以上对应的公钥，也证明了bitcoinj库是没有任何问题 同时我是用sawtooth自带的keygen工具去生成密钥对时候发现,sawtooth自带的生成公钥和私钥长度和以上测试用例的不一样，具体如下: 12私钥 ：&apos;20f34219eed055a8292767876e97cedc681cdee65f8d100f0c192d0b61cb13d6&apos; 公钥 ：&apos;02fe868857f1dcb31137b34c55cf1b6e031447b5fe7902e49a083eaf95c54aaecf&apos; 通过分析我们发现，example给出的例子使用的经过了base58编码的公私密钥对，而sawtooth原生的keygen则没有采用base58编码。因此如果使用java的bitcoinj库现有的方法能生成sawtooth keygen格式的公钥私钥对呢？这个就是本文的一个重点。 解决方法: 我们首先观察example里面的Signing 类，发现里面调用的方法都是来自于ECKey这个类的，通过分析，首先在ECKey类里面的私钥都是使用BigInteger表示的，而我们sawtooth keygen生成的私钥是16位Hex格式的String 因此我们需要使用方法把导入的String从16位Hex读入再变成BigInteger对象，再使用ECKey的fromPrivate((BigInteger privKey)方法，由BigInteger对象生成一个ECKey的对象。具体的fromPrivate()方法如下: 123public static ECKey fromPrivate(BigInteger privKey) &#123; return fromPrivate(privKey, true);&#125; 最后通过getPublicKeyAsHex()方法即可得到由16位hex编码的String 公钥 具体实现代码:getPublicKeyFromHex()12345public static String getPublicKeyFromHex(String key)&#123; BigInteger privateKeyBigInt = new BigInteger(key,16); ECKey privateKey = ECKey.fromPrivate(privateKeyBigInt); return privateKey.getPublicKeyAsHex();&#125; 实现的例子:main.java1234567891011121314151617import org.bitcoinj.core.ECKey;import java.math.BigInteger;public class main &#123; public static String getPublicKeyFromHex(String key)&#123; BigInteger privateKeyBigInt = new BigInteger(key,16); ECKey privateKey = ECKey.fromPrivate(privateKeyBigInt); return privateKey.getPublicKeyAsHex(); &#125; public static void main(String[] args) &#123; //此处我输入我上文提到的公钥 String privateKeyStr = "20f34219eed055a8292767876e97cedc681cdee65f8d100f0c192d0b61cb13d6"; System.out.println(getPublicKeyFromHex(privateKeyStr)); &#125;&#125; 程序执行结果: 程序执行结果102fe868857f1dcb31137b34c55cf1b6e031447b5fe7902e49a083eaf95c54aaecf 我们成功的使用java实现了sawtooth自带的keygen功能，除了keygen的通过随机数生成privatekey外，我们已经实现了把keygen生成的私钥生成回sawtooth keygen兼容的公钥格式]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>hyperledger</tag>
        <tag>sawtooth</tag>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决gnome3自己添加的程序dock栏图标重复问题]]></title>
    <url>%2F%E8%A7%A3%E5%86%B3gnome3%E8%87%AA%E5%B7%B1%E6%B7%BB%E5%8A%A0%E7%9A%84%E7%A8%8B%E5%BA%8Fdock%E6%A0%8F%E5%9B%BE%E6%A0%87%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[背景：最近我的主力笔记本Archlinux开始用Gnome3桌面，主要是Kde看腻了，Gnome3总体感觉还是非常好看的，这里先秀上一张我的Gnome3桌面，嘻嘻。但是Gnome3安装完后，我以前在Kde桌面的程序入口全部都没有了，包括我以前新建的一些程序快捷方式，因此只能按照freedesktop的标准去编写 .desktop 文件然后编写的时候发现一个问题，就是我的 .desktop 文件虽然能够在Gnome的所有程序找到，也可以添加到收藏夹但是存在一个问题，就是会出现如下当应用程序启动后多个图标问题。这种问题对于追求完美的我来说，怎么能够忍受呢？因此，下面教程将会用一个简单的方法去处理这个问题。 解决方案：我们首先来对比一下，其他没有问题的应用程序的.desktop是怎么编写的，和我们有什么不同。 以下是一个正常没有出现双图标的.desktop： 以下是我们出现双图标的eclipse的.desktop: 通过对比两图我们发现，正常的.desktop最下面有一行StartupWMClass=，这个也是我们今天的解决办法，下面，我们如何知道我们的StartupWMClass=需要填入什么呢，于是，我们需要接触一个新工具xprop WM_CLASS 当我们在终端执行以下命令: # yewei @ yewei in ~/yyw/code/ywandy.github.io on git:master x [0:45:13] $ xprop WM_CLASS 屏幕会出先一个像截图的 X ，然后这时候，我们用 X 去点击我们的eclipse窗口（对于其他应用一样，就去点击那个应用的窗口就好了） 此时的命令行会出现: # yewei @ yewei in ~/yyw/code/ywandy.github.io on git:master x [0:47:18] C:130 $ xprop WM_CLASS WM_CLASS(STRING) = "Eclipse", "Eclipse" 我们只需要把Eclipse填入我们的eclipse的.desktop最后一行即可，然后尝试启动eclipse最终的.desktop是这样的： 此时，自建的.desktop导致dock栏的双图标问题已经解决了: ##附录: 完整的eclipse.desktop文件： 123456789[Desktop Entry]Type=ApplicationName=Eclipse-cppComment=Eclipse Integrated Development EnvironmentIcon=/home/yewei/yyw/application/eclipse-cpp/icon.xpmExec=/home/yewei/yyw/application/eclipse-cpp/eclipseTerminal=falseCategories=Development;IDE;Java;StartupWMClass=Eclipse]]></content>
      <categories>
        <category>技巧总结</category>
      </categories>
      <tags>
        <tag>Gnome</tag>
        <tag>freedesktop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx通过反向代理的方法去访问Gitlab]]></title>
    <url>%2FNginx%E9%80%9A%E8%BF%87%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95%E5%8E%BB%E8%AE%BF%E9%97%AEGitlab.html</url>
    <content type="text"><![CDATA[背景:最近用为企业部署了Gitlab用来存放代码用。Gitlab是一个企业能够很方便的管理代码的工具，官方提供的安装配置也很方便的部署Gitlab 到企业的服务器Gitlab本身自带了Nginx，并且如果不改动任何配置的话，Gitlab默认会部署到80端口。由于企业在这个服务器有很多其他的web服务，要做到Gitlab和其他的web服务共存，那么需要做一点点修改 方案: 方法一：干掉Gitlab的内置Nginx，然后在外部安装nginx服务器，并且代理了Nginx的socket端口。 方法二：在外部的Nginx服务器做代理转发，这个方法不需要禁用Gitlab本身的Nginx服务，只需要在外部的Nginx做相关的改动即可。（由于不想改动太多，以及涉及到集成化的原因，就不打算动Gitlab内部的Nginx，方案二也就是本文介绍的方法，就是用我们外部的Nginx去代理转发请求到Gitlab的服务端口) 实现(方案二): 修改Gitlab的配置文件： 默认安装的Gitlab，配置文件在 :/etc/gitlab/gitlab.rb 修改Gitlab的监听端口号:nginx[&#39;listen_port&#39;] = 端口号 修改Gitlab的域名：external_url &#39;域名&#39;（注意，此处的域名不需要带上端口号，因为请求是被我们前级的Nginx处理的，然后把请求转发过来这个端口，对外访问而言，还是我们的前级Nginx的80端口) 最后执行 gitlab-ctrl reconfigure 让配置生效 配置Nginx服务器的站点配置文件 default.conf： 1234567891011121314151617181920212223upstream git&#123; # 域名对应 gitlab配置中的 external_url # 端口对应 gitlab 配置中的 nginx[&apos;listen_port&apos;] server 域名:端口;&#125;server&#123; listen 80; # 此域名是提供给最终用户的访问地址 server_name 域名; location / &#123; # 这个大小的设置非常重要，如果 git 版本库里面有大文件，设置的太小，文件push 会失败，根据情况调整 client_max_body_size 50m; proxy_redirect off; #以下确保 gitlab中项目的 url 是域名而不是 http://git，不可缺少 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 反向代理到 gitlab 内置的 nginx proxy_pass http://git; index index.html index.htm; &#125;&#125;]]></content>
      <categories>
        <category>技巧总结</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
        <tag>nginx</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
</search>
